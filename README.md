# AI Pet - Voice Assistant with PiCar-X Support

An interactive AI companion running on Raspberry Pi 5 with PiCar-X robot platform, featuring local LLM, speech recognition, and text-to-speech capabilities.

## Features

- ğŸ¤ **Voice Interaction** - Speak to your AI pet and get responses
- ğŸ¤– **Local LLM** - Runs Ollama locally (Gemma, TinyLlama, Phi-3)
- ğŸ—£ï¸ **Speech-to-Text** - Whisper.cpp for accurate transcription
- ğŸ”Š **Text-to-Speech** - Piper TTS for natural voice output
- ğŸ¨ **Animated Character** - Displays cute character animations
- ğŸ‘¤ **Face Recognition** - Recognizes and greets known users
- ğŸš— **PiCar-X Integration** - Voice-controlled robot movements
- ğŸ’¾ **Fully Local** - No cloud services required

## Hardware Support

- **Raspberry Pi 5** (4GB/8GB recommended)
- **PiCar-X Robot Platform** by SunFounder
- **USB Microphone** or I2S Microphone HAT
- **Speaker** (USB/Audio Jack/HAT)
- **Optional**: Camera module for face recognition

## Quick Start

### For Raspberry Pi 5 with PiCar-X:

See the comprehensive setup guide: [PICARX_SETUP.md](PICARX_SETUP.md)

### Basic Installation:

```bash
# Clone repository
git clone <repository-url> ai-pet
cd ai-pet

# Install dependencies
pip install -r requirements.txt

# Run setup script
bash install\ manual/setup.sh
```

### Run the Application:

```bash
# With PiCar-X support
cd stt/whisper.cpp/samples
python3 voice_loop_picarx.py

# Original version (no robot control)
python3 voice_loop3.py
```

## Documentation

- [PiCar-X Setup Guide](PICARX_SETUP.md) - Complete setup for Raspberry Pi 5 with PiCar-X
- [Installation Manual](install%20manual/install.md) - Basic installation instructions
- [Configuration Guide](stt/whisper.cpp/samples/config.py) - Configuration options

## Project Structure

```
ai-pet/
â”œâ”€â”€ stt/whisper.cpp/
â”‚   â”œâ”€â”€ samples/
â”‚   â”‚   â”œâ”€â”€ voice_loop_picarx.py  # Main app with PiCar-X
â”‚   â”‚   â”œâ”€â”€ voice_loop3.py        # Main app (original)
â”‚   â”‚   â”œâ”€â”€ picarx_control.py     # PiCar-X motor control
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration manager
â”‚   â”‚   â”œâ”€â”€ gui_frame.py          # Character animation
â”‚   â”‚   â””â”€â”€ face_r.py             # Face recognition
â”‚   â””â”€â”€ piper/                    # TTS engine
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ PICARX_SETUP.md               # Setup guide
â””â”€â”€ README.md                     # This file
```

## Voice Commands

### Conversation
- Talk naturally to your AI pet
- Ask questions, chat, or seek companionship

### Movement (PiCar-X mode)
- "Move forward" / "Go ahead"
- "Move backward" / "Go back"
- "Turn left" / "Go left"
- "Turn right" / "Go right"
- "Stop"

### Gestures
- "Nod your head" (yes gesture)
- "Shake your head" (no gesture)

## Configuration

Create a `config.json` file to customize settings:

```bash
cd stt/whisper.cpp/samples
python3 config.py create config.json
# Edit config.json with your preferences
```

Key configuration options:
- `enable_picarx`: Enable/disable robot control
- `picarx_simulation`: Test without hardware
- `llm_model`: Choose LLM model (gemma2:2b, tinyllama, etc.)
- `audio_device`: Set microphone device

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License. See the LICENSE file for details.

## Acknowledgments

- [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) - Fast speech recognition
- [Ollama](https://ollama.com) - Local LLM runtime
- [Piper TTS](https://github.com/rhasspy/piper) - Neural text-to-speech
- [SunFounder PiCar-X](https://www.sunfounder.com/products/picar-x) - Robot platform
